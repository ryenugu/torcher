{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=datasets.MNIST(\"\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "test=datasets.MNIST(\"\",train=False,download=True,transform=transforms.Compose(transforms.ToTensor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([7, 5, 1, 2, 7, 1, 8, 2, 4, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Digit 0: 5923 samples\n",
      "Digit 1: 6742 samples\n",
      "Digit 2: 5958 samples\n",
      "Digit 3: 6131 samples\n",
      "Digit 4: 5842 samples\n",
      "Digit 5: 5421 samples\n",
      "Digit 6: 5918 samples\n",
      "Digit 7: 6265 samples\n",
      "Digit 8: 5851 samples\n",
      "Digit 9: 5949 samples\n",
      "Digit 0: 9.87%\n",
      "Digit 1: 11.24%\n",
      "Digit 2: 9.93%\n",
      "Digit 3: 10.22%\n",
      "Digit 4: 9.74%\n",
      "Digit 5: 9.04%\n",
      "Digit 6: 9.86%\n",
      "Digit 7: 10.44%\n",
      "Digit 8: 9.75%\n",
      "Digit 9: 9.92%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Count the number of occurrences of each digit (0-9)\n",
    "label_counts = torch.bincount(train.targets)\n",
    "testcount = len(test)\n",
    "print(testcount)\n",
    "\n",
    "# Print the count for each digit\n",
    "for digit, count in enumerate(label_counts):\n",
    "    print(f\"Digit {digit}: {count} samples\")\n",
    "    \n",
    "# Calculate total number of samples\n",
    "total_samples = len(train)\n",
    "\n",
    "# Print the percentage distribution for each digit\n",
    "for digit, count in enumerate(label_counts):\n",
    "    percentage = (count.item() / total_samples) * 100\n",
    "    print(f\"Digit {digit}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[-2.2158, -2.2527, -2.3332, -2.4068, -2.2315, -2.2859, -2.2777, -2.4135,\n",
      "         -2.3595, -2.2712]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((28, 28))\n",
    "X = X.view(-1, 784)\n",
    "output = net(X)\n",
    "print(\"Output: \\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Count: 1\n",
      "Device 0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.097\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_examples = 0\n",
    "\n",
    "# Disable gradient computation to improve performance\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        input_data, target_label = data\n",
    "        \n",
    "        # Make predictions using the neural network\n",
    "        output = net(input_data.view(-1, 784))\n",
    "        \n",
    "        # Increment correct/total counter based on prediction accuracy\n",
    "        for predicted_class, actual_class in zip(output, target_label):\n",
    "            if torch.argmax(predicted_class) == actual_class:\n",
    "                correct_predictions += 1\n",
    "            total_examples += 1\n",
    "        \n",
    "# Print the final accuracy as a rounded decimal value with 3 places\n",
    "print(\"Accuracy:\", round(correct_predictions / total_examples, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mply\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(net(X[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m))[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as ply\n",
    "\n",
    "plt.imshow(X[2].view(28, 28))\n",
    "plt.show()\n",
    "\n",
    "print(torch.argmax(net(X[2].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3460],\n",
      "        [ 0.1754],\n",
      "        [ 0.1101],\n",
      "        [-0.4957],\n",
      "        [ 0.3900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the device as 'cuda' if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple model\n",
    "model = torch.nn.Linear(10, 1)\n",
    "\n",
    "# Move the model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Create some random input data and move it to GPU\n",
    "input_data = torch.randn(5, 10).to(device)\n",
    "\n",
    "# Perform forward pass\n",
    "output = model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
